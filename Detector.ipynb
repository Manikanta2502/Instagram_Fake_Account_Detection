{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pGJJ17Fi8_xo",
        "outputId": "1420e001-aa90-4d89-b959-38a14b0d266c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n"
      ],
      "metadata": {
        "id": "yiLLIv7s-5gK"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'filename.csv' with the actual path to your CSV file\n",
        "file_path = 'instagram.csv'\n",
        "\n",
        "# Read the CSV file into a DataFrame\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify that the data was loaded correctly\n",
        "print(data.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMyCiF1t-7B4",
        "outputId": "513fe2b7-2b6e-4d5c-ad5e-705c93a7ecc2"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   profile pic  nums/length username  fullname words  nums/length fullname  \\\n",
            "0            1                  0.27               0                   0.0   \n",
            "1            1                  0.00               2                   0.0   \n",
            "2            1                  0.10               2                   0.0   \n",
            "3            1                  0.00               1                   0.0   \n",
            "4            1                  0.00               2                   0.0   \n",
            "\n",
            "   name==username  description length  external URL  private  #posts  \\\n",
            "0               0                  53             0        0      32   \n",
            "1               0                  44             0        0     286   \n",
            "2               0                   0             0        1      13   \n",
            "3               0                  82             0        0     679   \n",
            "4               0                   0             0        1       6   \n",
            "\n",
            "   #followers  #follows  fake  \n",
            "0        1000       955     0  \n",
            "1        2740       533     0  \n",
            "2         159        98     0  \n",
            "3         414       651     0  \n",
            "4         151       126     0  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#addressing the outliers\n",
        "features_with_outliers = ['#posts', '#followers']\n",
        "\n",
        "for feature in features_with_outliers:\n",
        "    data[feature] = np.log1p(data[feature])"
      ],
      "metadata": {
        "id": "yHnZcv8iA0wI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Assuming 'data' is your DataFrame containing the dataset\n",
        "# Define features (X) and target variable (y)\n",
        "X = data.drop('fake', axis=1)  # Drop the column containing the target variable\n",
        "y = data['fake']  # Select only the column containing the target variable\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "iwomPrM-Bd2-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the scaler on the training data and transform the training features\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "\n",
        "# Transform the testing features using the scaler fitted on the training data\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Train the model on the scaled training data\n",
        "model.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Predict on the testing data\n",
        "y_pred = model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model's performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Evaluation:\")\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n"
      ],
      "metadata": {
        "id": "WpWIWlFZB1v6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2caa109-5ae4-4f38-d81e-4a15ff44f2b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Evaluation:\n",
            "Accuracy: 0.9310344827586207\n",
            "Precision: 0.9591836734693877\n",
            "Recall: 0.8867924528301887\n",
            "F1 Score: 0.9215686274509803\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
        "from sklearn.utils import class_weight\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "\n",
        "# Define class weights to address class imbalance\n",
        "class_weights = class_weight.compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
        "\n",
        "# Initialize Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "\n",
        "# Define hyperparameters for grid search\n",
        "param_grid = {\n",
        "    'C': [0.001, 0.01, 0.1, 1, 10, 100],  # Regularization parameter\n",
        "    'penalty': ['l1', 'l2']  # Regularization penalty\n",
        "}\n",
        "\n",
        "# Perform grid search with 5-fold stratified cross-validation\n",
        "grid_search = GridSearchCV(model, param_grid, cv=StratifiedKFold(n_splits=5), scoring='f1', verbose=1)\n",
        "\n",
        "# Fit grid search to the scaled training data\n",
        "grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Get best hyperparameters and corresponding model\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate best model on the testing data\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "print(\"Best Model Evaluation:\")\n",
        "print(\"Best Hyperparameters:\", best_params)\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)\n"
      ],
      "metadata": {
        "id": "APbzci7-CSv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59a66ce4-faa9-442d-f53d-cf1f1e69609e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 12 candidates, totalling 60 fits\n",
            "Best Model Evaluation:\n",
            "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
            "Accuracy: 0.9137931034482759\n",
            "Precision: 0.9574468085106383\n",
            "Recall: 0.8490566037735849\n",
            "F1 Score: 0.9\n",
            "\n",
            "Confusion Matrix:\n",
            "[[61  2]\n",
            " [ 8 45]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "30 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "30 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.92741576        nan 0.93369184        nan 0.93505489\n",
            "        nan 0.93346219        nan 0.9278329         nan 0.92545888]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install skl2onnx"
      ],
      "metadata": {
        "id": "WL3l3hugIZ9k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4b93794-6def-4682-c6d3-052b3baf34b3"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: skl2onnx in /usr/local/lib/python3.10/dist-packages (1.16.0)\n",
            "Requirement already satisfied: onnx>=1.2.1 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn>=0.19 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.2.2)\n",
            "Requirement already satisfied: onnxconverter-common>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from skl2onnx) (1.14.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (1.25.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx>=1.2.1->skl2onnx) (3.20.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxconverter-common>=1.7.0->skl2onnx) (24.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19->skl2onnx) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19->skl2onnx) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.19->skl2onnx) (3.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from skl2onnx import convert_sklearn\n",
        "from skl2onnx.common.data_types import FloatTensorType\n",
        "\n",
        "# Convert the model to ONNX format\n",
        "onnx_model = convert_sklearn(best_model, initial_types=[('input', FloatTensorType([None, X_train_scaled.shape[1]]))])\n",
        "\n",
        "# Save the ONNX model to a file\n",
        "with open('model.onnx', 'wb') as f:\n",
        "    f.write(onnx_model.SerializeToString())\n"
      ],
      "metadata": {
        "id": "l8ToM1qTEa5b"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install onnxruntime\n"
      ],
      "metadata": {
        "id": "g3aF_3ryJoIp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45586f35-7c24-418c-d340-db4a8051e541"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: onnxruntime in /usr/local/lib/python3.10/dist-packages (1.17.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.7)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import onnxruntime as rt\n",
        "\n",
        "# Load the ONNX model\n",
        "sess = rt.InferenceSession(\"model.onnx\")\n",
        "\n",
        "# Define the attribute names\n",
        "attribute_names = [\"profile pic(0 or 1)\", \"fullname words\", \"name==username(0 or 1)\", \"description length\", \"external URL(0 or 1)\", \"private(0 or 1)\", \"#posts\", \"#followers\", \"#follows\", \"nums/length fullname\", \"nums/length username\"]\n",
        "\n",
        "# Function to preprocess user input\n",
        "def preprocess_input(user_input):\n",
        "    # Preprocess the user input (e.g., convert to numpy array)\n",
        "    # Make sure to preprocess the input in the same way as the training data\n",
        "    user_input_processed = np.array(user_input)  # Assuming user_input is a list or array\n",
        "    return user_input_processed.astype(np.float32)\n",
        "\n",
        "# Function to scale input data\n",
        "def scale_input(input_data):\n",
        "    # Scale the input data using the same scaler used during training\n",
        "    input_data_scaled = scaler.transform(input_data.reshape(1, -1))  # Scale the input\n",
        "    return input_data_scaled\n",
        "\n",
        "# Function to make predictions\n",
        "def predict(input_data):\n",
        "    input_name = sess.get_inputs()[0].name\n",
        "    output_name = sess.get_outputs()[0].name\n",
        "    predictions = sess.run([output_name], {input_name: input_data})[0]\n",
        "    return predictions\n",
        "\n",
        "# Main function to take user input and make predictions\n",
        "def main():\n",
        "    # Take input for each attribute\n",
        "    user_input = []\n",
        "    for attribute_name in attribute_names:\n",
        "        if attribute_name == \"nums/length fullname\":\n",
        "            nums_fullname = float(input(\"Enter the number of numeric characters in the fullname: \"))\n",
        "            len_fullname = float(input(\"Enter the length of the fullname: \"))\n",
        "            nums_len_fullname = nums_fullname / len_fullname\n",
        "            user_input.append(nums_len_fullname)\n",
        "        elif attribute_name == \"nums/length username\":\n",
        "            nums_username = float(input(\"Enter the number of numeric characters in the username: \"))\n",
        "            len_username = float(input(\"Enter the length of the username: \"))\n",
        "            nums_len_username = nums_username / len_username\n",
        "            user_input.append(nums_len_username)\n",
        "        elif attribute_name == \"#posts\" or attribute_name == \"#followers\" or attribute_name == \"#follows\":\n",
        "            attribute_value = int(input(f\"Enter value for {attribute_name}: \"))\n",
        "            user_input.append(attribute_value)\n",
        "        else:\n",
        "            attribute_value = input(f\"Enter value for {attribute_name}: \")\n",
        "            user_input.append(float(attribute_value))\n",
        "\n",
        "    # Preprocess user input\n",
        "    input_data = preprocess_input(user_input)\n",
        "\n",
        "    # Scale input data\n",
        "    input_data_scaled = scale_input(input_data)\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = predict(input_data_scaled)\n",
        "\n",
        "    # Display predictions\n",
        "    predicted_class = \"fake\" if predictions[0] > 0.5 else \"not fake\"\n",
        "    print(\"Predicted class:\", predicted_class)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "Cfd7PTpyIXo7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f31c7a71-7ae4-4324-d07d-01f63e270db7"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter value for profile pic(0 or 1): 0\n",
            "Enter value for fullname words: 7\n",
            "Enter value for name==username(0 or 1): 0\n",
            "Enter value for description length: 34\n",
            "Enter value for external URL(0 or 1): 0\n",
            "Enter value for private(0 or 1): 1\n",
            "Enter value for #posts: 20\n",
            "Enter value for #followers: 437\n",
            "Enter value for #follows: 456\n",
            "Enter the number of numeric characters in the fullname: 0\n",
            "Enter the length of the fullname: 7\n",
            "Enter the number of numeric characters in the username: 4\n",
            "Enter the length of the username: 11\n",
            "Predicted class: not fake\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:439: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "The data set we trained is small and it may change the output for some cases\n"
      ],
      "metadata": {
        "id": "qBAmT1UTJiqU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}